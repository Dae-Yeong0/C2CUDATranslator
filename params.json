{"name":"C2CUDATranslator","tagline":"Automatic Conversion of Source Code for C to CUDA C.","body":"# Welcome to C2CUDATranslator.\r\nAs today in so many fields, computation is the main part of the algorithm and takes too much time in execution of the algorithm, it is necessary to parallelize the computation or reduce execution time. GPUs are widely used in (HPC) `High Performance Computing`. To achieve speedup, either we can increase clock frequency or multiple computation cores on the same chip. The clock speeds have reached the physical limit, so the use of many cores is the only way left to achieve speedup. As the `GPU` is growing demand of the Game Industry and large scientific computations, efforts have been made to take advantages to gain maximum utilization of the GPUs in computation. Though GPUs are widely used in Supercomputers today, they are not code transparent because one has to sit and code the algorithms in `CUDA C` to run them on `nVIDIA GPU`. So if we can have some `middle ware` that converts the C programs to CUDA, the end user gets `transparency`. I tried to develop a prototype compiler using `ANTLR` in visual studio that converts the C programs in CUDA C language. The thesis describes the literature survey in CUDA, different performance optimization strategies to reduce execution time, the Pattern approach to develop a translator for source code to source code translation on the basis of selection of codes using patterns, platforms to code such translator and platform comparison and choice and algorithm of translation. The Compiler Architecture and its implementation details are widely described in thesis. The thesis describes implementation of the complete `C2CUDATranslator`, testing and analysis of the developed compiler. The compiler takes input of C program and generates CUDA program. The thesis demonstrates the pattern approach for language to language translation and the compiler flow architecture. `C2CUDAranslator` covers a new way or a framework to implement new analysis algorithms to detect dependencies in the code. The thesis also covers neural network design for compiler learning and optimization of the translated code. The Neural Network helps compiler to take decision for selection of transformation and translation. Finally, the thesis covers outcome of the compiler, converted programs list, evaluation using parboil benchmark suite, performance graph of converted programs. It is concluded that the **C2CUDATranslator saves 95% of the development time in selected cases**. `C2CUDA Translator` converts C code to CUDA C. It is also a framework to develop analysis and dependency checking algorithms for other developers. \r\n\r\n# Developer's Guide\r\n\r\n`C2CUDATranslator` is very easy to work with. Developers are required to know C, CUDA C in detail in advance before using `C2CUDATranslator`. Additionally they are required to know `ANTLR` compulsory.\r\n\r\n## C.1 Getting Started\r\n\r\n`C2CUDATranslaor` is like a framework to develop and test various code analysis algorithms in the field of source code to source code translation.\r\n\r\n### C.1.1 C2CUDATranslator Project Structure \r\n\r\nThe design of the project is shown below. Developers can see the Visual 2008 Solution project as given design on project website.\r\n\r\n[Thesis Site](https://sites.google.com/a/nirmauni.ac.in/cudacodes/)\r\n\r\n## C.2 C2CUDATranslator development Details \r\n\r\n### C.2.1 Analysis Framework \r\n\r\nIn C2CUDATranslator there is a file `\"Analysis.cs\"` which contains analysis algorithms. One can write his/her own algorithm in this file as a class or new function and can call in the parser. But the namespace must be `C2CUDAranslator.Analysis`. \r\n\r\n### C.2.2 Translation Framework \r\n\r\nSimilarly, `C2CUDATranslator.Translation` is the framework that contains classes and codes for translation. Developers will find FOR, BLOCK etc. classes. They may contain properties like `LOOP`.`index`, `LOOP.IsNestLoop` etc. \r\n\r\n### C.2.3 Use framework \r\n\r\nDevelopers can use collections those contains read only, write-only variables and can use them in conditions in making analysis algorithms.\r\n\r\n# User's Guide\r\n\r\n`C2CUDATranslator` is very easy to use. Users are required to know C in advance before using `C2CUDATranslator`.\r\n\r\n## B.1 Getting Started \r\n\r\n### B.1.1 Input and Output of C2CUDATranslator\r\n\r\n```\r\n**Input.file** - input to translator (C File) \r\n**Output.file** - output of the translator (CUDA File)\r\n```\r\n\r\nFirst, copy C program to input.file and run the translator. After running the translator copy CUDA code that has been converted or copy content of output.file. Put them in CUDA project. Run the project. \r\n\r\n## B.2 C2CUDATranslator input Details \r\n\r\n### B.2.1 Kernel Outlining\r\n\r\nThe kernel is the code to be ported on the GPU. So, First identify the code you want to run on GPU. It may be some computation code such as loops. Now, write `\"#pragma kernel_start\"` before that code and at the end of the code write `\"#pragma kernel_end\"`.\r\n\r\n**Example**\r\n\r\n```\r\n#pragma kernel_start \r\nfor (i = 1; i <= 100; ++i) \r\n{ \r\n   for (j = 0; j < 100; ++j) \r\n     { \r\n       a [i ] [j ] = b[i ] [j ] + c[i ] [j ]; \r\n     } \r\n} \r\n#pragma kernel_end\r\n```\r\n\r\nB.2.2 Kernel Variables \r\n\r\nKernel variables are the variables which are copied to/from host/devices. User can specify them in their code by writing `\"kernel\"` in the declaration of that variable.\r\n\r\n**Example**\r\n\r\n```\r\n$ int a [100 ] [100 ]; \r\n$ int b [100 ] [100 ]; \r\n$ int c [100 ] [100 ];\r\n```\r\n\r\na,b & c arrays are used in kernel. So, we will write them as\r\n\r\n```\r\n$ kernel int a[100 ] [100 ]; \r\n$ kernel int b[100 ] [100 ]; \r\n$ kernel int c[100 ] [100 ];\r\n```\r\n\r\nB.2.3 Kernel local Variables\r\n\r\nIf there are some local variables in the kernel code, they does not need to be copied to/from host/device. They can be initialized in GPU. We can write `\"local kernel\"` before the declaration statements of them.\r\n\r\n**Example**\r\n\r\n```\r\n$ int n=3; \r\n$ int P=100;\r\n```\r\n\r\nn & P are local variables used in kernel region. So, we will write them as \r\n\r\n```\r\n$ local kernel int n=3; \r\n$ local kernel int P=100;\r\n```\r\n\r\n### Technologies Used\r\n```\r\n$ Java - ANTLR.jar\r\n$ C# ASP.NET\r\n$ Visual Studio\r\n$ STG files with ANTLR - ANOTHER TOOL FOR LANGUAGE RECOGNITION\r\n$ ANTLRWorks\r\n$ Microsoft SQL Server \r\n```\r\n### Github page\r\n\r\n[C2CUDATranslator on Github](https://github.com/prem30488/C2CUDATranslator)\r\n\r\n### Google Page\r\n\r\n[C2CUDATranslator on Google](http://code.google.com/p/c2cudatranslator/)\r\n\r\n### Thesis Website\r\n\r\n[C2CUDATranslator Thesis Website](https://sites.google.com/a/nirmauni.ac.in/cudacodes/ongoing-projects/automatic-conversion-of-source-code-for-c-to-cuda-c)\r\n\r\n### Authors and Contributors\r\n\r\n**Author :** (@prem30488) Parth Trivedi \r\n\r\n### Support or Contact\r\nHaving trouble with Pages? Check out the documentation at https://sites.google.com/a/nirmauni.ac.in/cudacodes/ongoing-projects/automatic-conversion-of-source-code-for-c-to-cuda-c or contact prem30488@gmail.com and weâ€™ll help you sort it out.\r\n","google":"UA-32478424-5","note":"Don't delete this file! It's used internally to help with page regeneration."}